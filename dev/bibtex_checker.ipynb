{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "id": "WreoZMPfY-I8"
   },
   "outputs": [],
   "source": [
    "from unidecode import unidecode as decode\n",
    "import bibtexparser as bp\n",
    "import numpy as np\n",
    "import re\n",
    "from string import ascii_lowercase\n",
    "import itertools\n",
    "\n",
    "from urllib import request as get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "nGkLxVvarNcb"
   },
   "outputs": [],
   "source": [
    "def remove_accents_and_hyphens(s):\n",
    "    replace = {'{\\\\l}': 'l',\n",
    "               '{\\\\o}': 'o',\n",
    "               '{\\\\i}': 'i',\n",
    "               '{\\\\t}': 't'}\n",
    "    for key, val in replace.items():\n",
    "        s = s.replace(key, val)\n",
    "    \n",
    "    accents = r'''\\{?\\\\[`'^\"~=.uvHtcdbkr]?\\s?\\{?\\\\?(\\w*)\\}?'''\n",
    "    accented_chars = [x for x in re.finditer(accents, s)]\n",
    "    \n",
    "    s_list = [c for c in s]\n",
    "    hyphen = '-'\n",
    "    for a in accented_chars:\n",
    "        next_len = a.end() - a.start()\n",
    "        s_list[a.start()] = a.group(1)\n",
    "        s_list[(a.start() + 1):a.end()] = hyphen * (next_len - 1)\n",
    "    \n",
    "    return ''.join([c for c in s_list if c != hyphen])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "1lifLiOylvbG"
   },
   "outputs": [],
   "source": [
    "def match(names, template):\n",
    "    #check if list of strings names contains a match to the potentially multi-word\n",
    "    #template.  return the position of the start of the left-most match\n",
    "    template = template.split(' ')\n",
    "    for i, x in enumerate(names[:len(names) - len(template) + 1]):\n",
    "        found_match = False\n",
    "        for j, t in enumerate(template):\n",
    "            if names[i + j].lower() != t:\n",
    "                found_match = False\n",
    "                break\n",
    "            else:\n",
    "                found_match = True\n",
    "        if found_match:\n",
    "            return i\n",
    "    return -1\n",
    "\n",
    "prefixes = ['de', 'da', 'di', 'von', 'zu', 'van', 'du', 'des',\n",
    "            'del', 'de la', 'della', 'la', 'le', 'der', 'af',\n",
    "            'st.', 'saint', 'st', 'dom', 'do', 'das', 'dos', 'of', 'al',\n",
    "            'el', 'dei', 'tot', 'thoe', 'aw', 'na', 'sri', 'phra',\n",
    "            'si', 'shri', 'lo', 'no', 'op', 'lopes', 'gonzalez', 'vom', 'castro']\n",
    "\n",
    "suffixes = ['sr.', 'jr.', 'sr', 'jr', 'senior', 'junior', 'iii', 'iv', 'v', \n",
    "            'vi', 'vii', 'viii', 'ix', 'x', 'the', 'third', 'fourth', 'fifth',\n",
    "            'sixth', 'seventh', 'eighth', 'ninth', 'tenth', 'great']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "ZLQJyV_NKW0w"
   },
   "outputs": [],
   "source": [
    "def remove_curlies(s): #only removes *matching* curly braces\n",
    "    for i, c in enumerate(s):    \n",
    "        if c == '{':\n",
    "            j = i\n",
    "            \n",
    "            curly_count = 1\n",
    "            while (j < len(s) - 1):\n",
    "                j += 1\n",
    "                if s[j] == '{':\n",
    "                    curly_count += 1\n",
    "\n",
    "                if s[j] == '}':\n",
    "                    curly_count -= 1\n",
    "\n",
    "                if curly_count == 0:\n",
    "                    break\n",
    "\n",
    "            if curly_count == 0:\n",
    "                return remove_curlies(s[:i] + ''.join(s[(i+1):j].split(' ')) + s[(j+1):])\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "a5Alp9RDzIsU"
   },
   "outputs": [],
   "source": [
    "def remove_non_letters(s):\n",
    "    remove_chars = [',', '.', '!', '?', \"'\", '\"', '{', '}', '-']    \n",
    "    for c in remove_chars:\n",
    "        s = s.replace(c, '')\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "qE7Ch9hhrqgL"
   },
   "outputs": [],
   "source": [
    "def rearrange(name):\n",
    "    original_name = name\n",
    "\n",
    "    #remove suffixes and convert to list\n",
    "    name = [remove_non_letters(x.strip()) for x in name.split(',')]\n",
    "    sxs = [n for n in name if n.lower() in suffixes]\n",
    "    name = [n for n in name if n.lower() not in suffixes]\n",
    "\n",
    "    if len(name) == 2: #last, first (+ middle)\n",
    "        x = ' '.join([name[1], name[0]])\n",
    "    elif len(name) == 1: #first (+ middle) + last\n",
    "        x = name[0]\n",
    "    elif len(name) == 0:\n",
    "        raise Exception(f'no non-suffix names: {original_name}')\n",
    "    elif len(name) > 2:\n",
    "        raise Exception(f'too many commas: {original_name}')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "MmJCn3oROIu6"
   },
   "outputs": [],
   "source": [
    "def last_name(names):\n",
    "    #remove suffixes and non-letters\n",
    "    names = [remove_non_letters(n) for n in rearrange(names).split(' ') if not (n.lower() in suffixes)]\n",
    "\n",
    "    #start at the end and move backward\n",
    "    x = []\n",
    "    found_prefix = False\n",
    "    for n in reversed(names):\n",
    "        if n.lower() in prefixes:\n",
    "            found_prefix = True\n",
    "        elif found_prefix or len(x) > 0:\n",
    "            break\n",
    "        x.append(n)\n",
    "    if found_prefix:\n",
    "        return ''.join(reversed(x))\n",
    "    else:\n",
    "        return x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "24P8HXnYwp2R"
   },
   "outputs": [],
   "source": [
    "def authors2key(authors, year):\n",
    "    def key(author):\n",
    "        #convert accented unicode characters to closest ascii equivalent\n",
    "        author = decode(author)\n",
    "\n",
    "        #re-arrange author name to FIRST [MIDDLE] LAST [SUFFIX]\n",
    "        author = remove_accents_and_hyphens(author)\n",
    "        author = remove_curlies(author)\n",
    "\n",
    "        #get first 4 letters of last name\n",
    "        return last_name(author)[:4]\n",
    "    \n",
    "    yr_str = str(year)[-2:]\n",
    "    \n",
    "    authors = authors.split(' and ')\n",
    "    if len(authors) == 0:\n",
    "        raise Exception('Author information missing, no key generated')\n",
    "    elif len(authors) == 1:\n",
    "        return key(authors[0]) + yr_str\n",
    "    elif len(authors) == 2:\n",
    "        return key(authors[0]) + key(authors[1]) + yr_str\n",
    "    elif len(authors) >= 3:\n",
    "        return key(authors[0]) + 'Etal' + yr_str\n",
    "    else:\n",
    "        raise Exception('Something went wrong...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "id": "Cf4F1qu8xsan"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entry type webpage not standard. Not considered.\n",
      "Entry type webpage not standard. Not considered.\n"
     ]
    }
   ],
   "source": [
    "bibfile = '../memlab.bib'\n",
    "parser = bp.bparser.BibTexParser(ignore_nonstandard_types=True, common_strings=True, homogenize_fields=True)\n",
    "\n",
    "with open(bibfile, 'r') as b:\n",
    "    bibdata = bp.load(b, parser=parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "id": "E7_JykrNejFQ"
   },
   "outputs": [],
   "source": [
    "bd = bibdata.get_entry_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "id": "l6WZ6axmhiwq"
   },
   "outputs": [],
   "source": [
    "#get all fields\n",
    "fields = {}\n",
    "for k in bd.keys():\n",
    "    next_entry = bd[k]\n",
    "    for field, vals in next_entry.items():\n",
    "        if not (field in fields.keys()):\n",
    "            fields[field] = [vals]\n",
    "        else:\n",
    "            fields[field].append(vals)\n",
    "\n",
    "for k in fields.keys():\n",
    "    fields[k] = list(np.unique(fields[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "id": "GFlECp9k45wX"
   },
   "outputs": [],
   "source": [
    "def get_vals(bd, field):\n",
    "    def safe_get(item, field):\n",
    "        if field in item.keys():\n",
    "            return item[field]\n",
    "        else:\n",
    "            return ''\n",
    "    \n",
    "    return [safe_get(i, field) for k, i in bd.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "id": "DNpqFsebUQLa"
   },
   "outputs": [],
   "source": [
    "def same_id(a, b, ignore_special=False):\n",
    "    if ignore_special and (('\\\\' in a) or ('\\\\' in b)):\n",
    "        return True\n",
    "    \n",
    "    if len(a) > len(b):\n",
    "        return same_id(b, a)\n",
    "    elif a == b:\n",
    "        return True\n",
    "    else:\n",
    "        return a == b[:len(a)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "id": "FoJMMQ8kyGwu"
   },
   "outputs": [],
   "source": [
    "authors = get_vals(bd, 'author')\n",
    "years = get_vals(bd, 'year')\n",
    "ids = get_vals(bd, 'ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "id": "BzxiFKxw5Y-N"
   },
   "outputs": [],
   "source": [
    "gen_ids = [authors2key(a, y) for a, y in zip(authors, years)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ucd05y6s5xdu",
    "outputId": "94ca107d-240b-4263-f4a5-689c00b30eeb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Congrats!  No keys to fix.\n"
     ]
    }
   ],
   "source": [
    "#check keys\n",
    "tofix = [f'{h}. [{i}] should be [{g}]' for i, g, h in zip(ids, gen_ids, range(0, len(ids))) if not same_id(i, g, ignore_special=False)] #check these over carefully...\n",
    "if len(tofix) == 0:\n",
    "    print('Congrats!  No keys to fix.')\n",
    "else:\n",
    "    print(f'Need to fix {len(tofix)} keys: \\n')\n",
    "    print('\\n'.join(tofix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def duplicate_inds(x):\n",
    "    # for the list x, return a new list containing 0 or more\n",
    "    # lists of the indices of matching (non-unique) elements\n",
    "    y = []\n",
    "    unique_vals, counts = np.unique(x, return_counts=True)\n",
    "    for v in [v for i, v in enumerate(unique_vals) if counts[i] > 1]:\n",
    "        y.append([i for i, j in enumerate(x) if j == v])\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = []\n",
    "duplicate_title_inds = duplicate_inds(titles)\n",
    "\n",
    "last_names = [' and '.join([last_name(a) for a in authors[i].split(' and ') if not (a in ignore_authors)]) for i in range(len(authors))]\n",
    "duplicate_authors = duplicate_inds(last_names)\n",
    "\n",
    "for i in duplicate_title_inds:\n",
    "    duplicate_author_inds = duplicate_inds([last_names[j] for j in i])\n",
    "    for a in duplicate_author_inds:\n",
    "        duplicates.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Congrats, no duplicates!\n"
     ]
    }
   ],
   "source": [
    "if len(duplicates) > 0:\n",
    "    for d in duplicates:\n",
    "        print(f'Duplicate IDs [ind, key]: {[[i, ids[i]] for i in d]}')\n",
    "else:\n",
    "    print('Congrats, no duplicates!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key_suffixes(n):\n",
    "    #source: https://stackoverflow.com/questions/29351492/how-to-make-a-continuous-alphabetic-list-python-from-a-z-then-from-aa-ab-ac-e/29351603\n",
    "    if n <= 1:\n",
    "        return ''\n",
    "    \n",
    "    def generate_id():\n",
    "        i = 1\n",
    "        while True:\n",
    "            for s in itertools.product(ascii_lowercase, repeat=i):\n",
    "                yield ''.join(s)\n",
    "            i += 1\n",
    "    \n",
    "    gen = generate_id()\n",
    "    \n",
    "    def helper():\n",
    "        for s in gen:\n",
    "            return s\n",
    "    \n",
    "    return [helper() for i in range(n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Adey67', 'Adey67b']"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(np.array(ids)[duplicate_inds(gen_ids)[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check bibtex keys. Duplicates should be assigned a suffix of 'a', 'b', etc.\n",
    "#If keys match aside from suffix then still allow the bibtex file to \"pass\"\n",
    "#as long as all \"matching\" keys are unique and all have suffixes and the \n",
    "#suffixes span a, b, c, ..., etc. without gaps\n",
    "\n",
    "def check_keys(ids, gen_ids):\n",
    "    checked = []\n",
    "    bad_keys = []\n",
    "    \n",
    "    #for duplicate base keys, ensure correct suffixes\n",
    "    same_base = duplicate_inds(gen_ids)\n",
    "    for inds in same_base:\n",
    "        next_base = gen_ids[inds[0]]\n",
    "        target_keys = [next_base + x for x in get_key_suffixes(len(inds))]\n",
    "        actual_keys = list(np.array(ids)[inds])\n",
    "        actual_keys.sort()\n",
    "        \n",
    "        for a, t in zip(actual_keys, target_keys):\n",
    "            checked.append(a)\n",
    "            if not (a == t): #FIXME: the check isn't quite right-- if a is *somewhere* in target_keys, it could still be OK\n",
    "                bad_keys.append([a, t]) #instead, figure out which keys are present and/or duplicated and/or missing.\n",
    "                                #if there's an extra actual key (not in target_keys), rename it to one of the \"free\"\n",
    "                                #target keys, leaving all other actual keys unchanged\n",
    "        \n",
    "    #for non-duplicate base keys, ensure *no* suffixes\n",
    "    for i, g in zip(ids, gen_ids):\n",
    "        if i not in checked:\n",
    "            if not (i == g):\n",
    "                bad_keys.append([i, g])\n",
    "    \n",
    "    return bad_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250 incorrect keys found:\n",
      "\n",
      "Adey67 should be renamed to Adey67a\n",
      "AndeEtal04 should be renamed to AndeEtal04a\n",
      "AndeEtal98 should be renamed to AndeEtal98a\n",
      "AndeEtal99 should be renamed to AndeEtal99a\n",
      "AndeEtal99a should be renamed to AndeEtal99b\n",
      "AndeEtal99b should be renamed to AndeEtal99c\n",
      "Bala98 should be renamed to Bala98a\n",
      "BarrEtal12 should be renamed to BarrEtal12a\n",
      "BarrEtal12a should be renamed to BarrEtal12b\n",
      "BarrEtal12b should be renamed to BarrEtal12c\n",
      "BartEtal04 should be renamed to BartEtal04a\n",
      "BartEtal04a should be renamed to BartEtal04b\n",
      "BartEtal04b should be renamed to BartEtal04c\n",
      "BartEtal11 should be renamed to BartEtal11a\n",
      "BartEtal11a should be renamed to BartEtal11b\n",
      "BernEtal01 should be renamed to BernEtal01a\n",
      "BernEtal01a should be renamed to BernEtal01b\n",
      "Blan86 should be renamed to Blan86a\n",
      "Blan86a should be renamed to Blan86b\n",
      "BrowEtal07 should be renamed to BrowEtal07a\n",
      "BrunEtal02 should be renamed to BrunEtal02a\n",
      "BrunEtal02a should be renamed to BrunEtal02b\n",
      "BrunEtal08 should be renamed to BrunEtal08a\n",
      "BrunEtal08a should be renamed to BrunEtal08b\n",
      "BuckEtal98 should be renamed to BuckEtal98a\n",
      "BurgEtal01 should be renamed to BurgEtal01a\n",
      "BurgEtal01Neuroimage should be renamed to BurgEtal01b\n",
      "CoheEtal08 should be renamed to CoheEtal08a\n",
      "CoheEtal09 should be renamed to CoheEtal09a\n",
      "Crai68 should be renamed to Crai68a\n",
      "CrisShif04 should be renamed to CrisShif04a\n",
      "CronEtal98 should be renamed to CronEtal98a\n",
      "CronEtal98a should be renamed to CronEtal98b\n",
      "CronEtal98b should be renamed to CronEtal98c\n",
      "CurrEtal06 should be renamed to CurrEtal06a\n",
      "CurrEtal06a should be renamed to CurrEtal06b\n",
      "DamiEtal99 should be renamed to DamiEtal99a\n",
      "DamiEtal99a should be renamed to DamiEtal99b\n",
      "EichEtal94 should be renamed to EichEtal94a\n",
      "EichEtal94a should be renamed to EichEtal94b\n",
      "Este86 should be renamed to Este86a\n",
      "FellEtal01 should be renamed to FellEtal01a\n",
      "FellEtal01a should be renamed to FellEtal01b\n",
      "FellEtal06 should be renamed to FellEtal06a\n",
      "FellEtal06a should be renamed to FellEtal06b\n",
      "FernEtal99 should be renamed to FernEtal99a\n",
      "FranEtal04 should be renamed to FranEtal04a\n",
      "FranEtal06 should be renamed to FranEtal06a\n",
      "FranEtal06a should be renamed to FranEtal06b\n",
      "FranEtal06b should be renamed to FranEtal06c\n",
      "FranEtal07 should be renamed to FranEtal07a\n",
      "Free06 should be renamed to Free06a\n",
      "Free06a should be renamed to Free06b\n",
      "FreeEtal03 should be renamed to FreeEtal03a\n",
      "FreeEtal03a should be renamed to FreeEtal03b\n",
      "FreeEtal03b should be renamed to FreeEtal03c\n",
      "FrieEtal01 should be renamed to FrieEtal01a\n",
      "FrieEtal02 should be renamed to FrieEtal02a\n",
      "FrinEtal06 should be renamed to FrinEtal06a\n",
      "FrinEtal06NeuroReport should be renamed to FrinEtal06b\n",
      "Gree86 should be renamed to Gree86a\n",
      "Gree86a should be renamed to Gree86b\n",
      "GrifEtal07 should be renamed to GrifEtal07a\n",
      "GrifEtal07a should be renamed to GrifEtal07b\n",
      "GrifEtal07b should be renamed to GrifEtal07c\n",
      "GrilEtal06 should be renamed to GrilEtal06a\n",
      "GrilEtal06a should be renamed to GrilEtal06b\n",
      "HalgEtal78 should be renamed to HalgEtal78a\n",
      "HansEtal12 should be renamed to HansEtal12a\n",
      "HealEtal12 should be renamed to HealEtal12a\n",
      "HealEtal14 should be renamed to HealEtal14a\n",
      "Hens98 should be renamed to Hens98a\n",
      "Hens98a should be renamed to Hens98b\n",
      "HensEtal00 should be renamed to HensEtal00a\n",
      "HensEtal00a should be renamed to HensEtal00b\n",
      "HescEtal13 should be renamed to HescEtal13a\n",
      "HescEtal13a should be renamed to HescEtal13b\n",
      "HillEtal11 should be renamed to HillEtal11a\n",
      "HillEtal11a should be renamed to HillEtal11b\n",
      "HockCris96 should be renamed to HockCris96a\n",
      "HowaEtal06 should be renamed to HowaEtal06a\n",
      "HowaEtal06e should be renamed to HowaEtal06b\n",
      "HowaEtal07 should be renamed to HowaEtal07a\n",
      "HowaEtal07c should be renamed to HowaEtal07b\n",
      "HowaEtal08 should be renamed to HowaEtal08a\n",
      "HowaEtal08a should be renamed to HowaEtal08b\n",
      "HowaEtal96 should be renamed to HowaEtal96a\n",
      "JacoEtal05 should be renamed to JacoEtal05a\n",
      "JacoEtal10 should be renamed to JacoEtal10a\n",
      "Jahn72 should be renamed to Jahn72a\n",
      "JeewEtal08 should be renamed to JeewEtal08a\n",
      "JeewEtal08a should be renamed to JeewEtal08b\n",
      "JerbEtal09 should be renamed to JerbEtal09a\n",
      "JerbEtal09a should be renamed to JerbEtal09b\n",
      "JerbEtal09b should be renamed to JerbEtal09c\n",
      "John72 should be renamed to John72a\n",
      "JohnRedi07 should be renamed to JohnRedi07a\n",
      "JohnRedi07a should be renamed to JohnRedi07b\n",
      "JoneWils05 should be renamed to JoneWils05a\n",
      "KahaEtal05 should be renamed to KahaEtal05a\n",
      "KahaEtal99 should be renamed to KahaEtal99a\n",
      "KaisEtal07 should be renamed to KaisEtal07a\n",
      "KaisEtal07a should be renamed to KaisEtal07b\n",
      "KellEtal10 should be renamed to KellEtal10a\n",
      "KellEtal10a should be renamed to KellEtal10b\n",
      "KleiEtal07 should be renamed to KleiEtal07a\n",
      "KleiEtal07a should be renamed to KleiEtal07b\n",
      "KlimEtal01 should be renamed to KlimEtal01a\n",
      "KlimEtal01a should be renamed to KlimEtal01b\n",
      "KlimEtal97 should be renamed to KlimEtal97a\n",
      "KreiEtal00 should be renamed to KreiEtal00a\n",
      "KreiEtal00a should be renamed to KreiEtal00b\n",
      "KrieEtal08 should be renamed to KrieEtal08a\n",
      "KuhlEtal12 should be renamed to KuhlEtal12a\n",
      "LachEtal00 should be renamed to LachEtal00a\n",
      "LachEtal00a should be renamed to LachEtal00b\n",
      "LachEtal07 should be renamed to LachEtal07a\n",
      "LeeEtal05 should be renamed to LeeEtal05a\n",
      "LegaEtal11 should be renamed to LegaEtal11a\n",
      "LegaEtal11a should be renamed to LegaEtal11b\n",
      "LeunBors87 should be renamed to LeunBors87a\n",
      "LeunBors87a should be renamed to LeunBors87b\n",
      "LeutEtal04 should be renamed to LeutEtal04a\n",
      "LeutEtal04a should be renamed to LeutEtal04b\n",
      "LeutEtal05 should be renamed to LeutEtal05a\n",
      "LeutEtal05a should be renamed to LeutEtal05b\n",
      "LeutEtal07 should be renamed to LeutEtal07a\n",
      "LeutEtal07a should be renamed to LeutEtal07b\n",
      "LimoEtal95 should be renamed to LimoEtal95a\n",
      "LimoEtal95a should be renamed to LimoEtal95b\n",
      "LimoEtal95b should be renamed to LimoEtal95c\n",
      "LohnEtal11 should be renamed to LohnEtal11a\n",
      "LohnEtal11a should be renamed to LohnEtal11b\n",
      "LongEtal11 should be renamed to LongEtal11a\n",
      "LongEtal11a should be renamed to LongEtal11b\n",
      "MannEtal09 should be renamed to MannEtal09a\n",
      "MarkEtal95 should be renamed to MarkEtal95a\n",
      "MarkEtal95a should be renamed to MarkEtal95b\n",
      "MartEtal09 should be renamed to MartEtal09a\n",
      "MartEtal09a should be renamed to MartEtal09b\n",
      "McClEtal04 should be renamed to McClEtal04a\n",
      "McClEtal04a should be renamed to McClEtal04b\n",
      "McClEtal04b should be renamed to McClEtal04c\n",
      "McNaEtal89 should be renamed to McNaEtal89a\n",
      "McNaEtal92 should be renamed to McNaEtal92a\n",
      "MillEtal07 should be renamed to MillEtal07a\n",
      "MillEtal07a should be renamed to MillEtal07b\n",
      "MillEtal07b should be renamed to MillEtal07c\n",
      "MillEtal07c should be renamed to MillEtal07d\n",
      "MillEtal07d should be renamed to MillEtal07e\n",
      "MillEtal09 should be renamed to MillEtal09a\n",
      "MillEtal09a should be renamed to MillEtal09b\n",
      "MillEtal12b should be renamed to MillEtal12a\n",
      "MillEtal12c should be renamed to MillEtal12b\n",
      "MontEtal08 should be renamed to MontEtal08a\n",
      "MontEtal08a should be renamed to MontEtal08b\n",
      "MontEtal08b should be renamed to MontEtal08c\n",
      "MormEtal08 should be renamed to MormEtal08a\n",
      "Murd63 should be renamed to Murd63a\n",
      "Murd85 should be renamed to Murd85a\n",
      "Murd92 should be renamed to Murd92a\n",
      "Murd95 should be renamed to Murd95a\n",
      "Nair92 should be renamed to Nair92a\n",
      "Neat93 should be renamed to Neat93a\n",
      "NelsEtal98 should be renamed to NelsEtal98a\n",
      "NichEtal06 should be renamed to NichEtal06a\n",
      "NormEtal06 should be renamed to NormEtal06a\n",
      "PalvEtal05 should be renamed to PalvEtal05a\n",
      "PastEtal08 should be renamed to PastEtal08a\n",
      "PastEtal08a should be renamed to PastEtal08b\n",
      "PateEtal12 should be renamed to PateEtal12a\n",
      "PateEtal12a should be renamed to PateEtal12b\n",
      "Penf58 should be renamed to Penf58a\n",
      "Penf58a should be renamed to Penf58b\n",
      "Pete66 should be renamed to Pete66a\n",
      "Pete66a should be renamed to Pete66b\n",
      "PeteEtal62 should be renamed to PeteEtal62a\n",
      "PeteEtal62a should be renamed to PeteEtal62b\n",
      "RaaiShif81 should be renamed to RaaiShif81a\n",
      "Radv99 should be renamed to Radv99a\n",
      "RatcEtal04 should be renamed to RatcEtal04a\n",
      "RayEtal08 should be renamed to RayEtal08a\n",
      "RayEtal08a should be renamed to RayEtal08b\n",
      "RayEtal08b should be renamed to RayEtal08c\n",
      "RayEtal08c should be renamed to RayEtal08d\n",
      "RayMaun11 should be renamed to RayMaun11a\n",
      "RoedEtal01 should be renamed to RoedEtal01a\n",
      "RoedKarp06 should be renamed to RoedKarp06a\n",
      "RoedKarp06a should be renamed to RoedKarp06b\n",
      "RushEtal02 should be renamed to RushEtal02a\n",
      "SchaEtal08 should be renamed to SchaEtal08a\n",
      "Schw78 should be renamed to Schw78a\n",
      "Schw78a should be renamed to Schw78b\n",
      "Shif70 should be renamed to Shif70a\n",
      "Smit02 should be renamed to Smit02a\n",
      "SpieEtal01 should be renamed to SpieEtal01a\n",
      "SpieEtal01Brain should be renamed to SpieEtal01b\n",
      "SquiEtal04 should be renamed to SquiEtal04a\n",
      "SrinEtal06 should be renamed to SrinEtal06a\n",
      "Ster01 should be renamed to Ster01a\n",
      "Ster01a should be renamed to Ster01b\n",
      "Ster98 should be renamed to Ster98a\n",
      "Ster98a should be renamed to Ster98b\n",
      "Ster98b should be renamed to Ster98c\n",
      "SterEtal96 should be renamed to SterEtal96a\n",
      "StreWixt98 should be renamed to StreWixt98a\n",
      "SummMang05 should be renamed to SummMang05a\n",
      "Tulv02 should be renamed to Tulv02a\n",
      "Tulv02a should be renamed to Tulv02b\n",
      "Tulv02b should be renamed to Tulv02c\n",
      "Tulv85 should be renamed to Tulv85a\n",
      "Tulv85a should be renamed to Tulv85b\n",
      "Tulv85b should be renamed to Tulv85c\n",
      "Unde72 should be renamed to Unde72a\n",
      "UnswEtal12 should be renamed to UnswEtal12a\n",
      "UnswEtal13 should be renamed to UnswEtal13a\n",
      "UnswEtal13a should be renamed to UnswEtal13b\n",
      "VanOEtal03 should be renamed to VanOEtal03a\n",
      "VoytEtal10 should be renamed to VoytEtal10a\n",
      "WallEtal01 should be renamed to WallEtal01a\n",
      "WatrEtal13 should be renamed to WatrEtal13a\n",
      "WatrEtal13a should be renamed to WatrEtal13b\n",
      "WillEtal05 should be renamed to WillEtal05a\n",
      "Wixt07 should be renamed to Wixt07a\n",
      "WuEtal00 should be renamed to WuEtal00a\n",
      "YassEtal11 should be renamed to YassEtal11a\n",
      "YassEtal11c should be renamed to YassEtal11b\n",
      "Yone99 should be renamed to Yone99a\n",
      "LeonEtal should be renamed to LeonEtal15\n",
      "HeusEtal17b should be renamed to HeusEtal17\n",
      "Broa57b should be renamed to Broa57\n",
      "vanVEtal07a should be renamed to vanVEtal07\n",
      "GothEtal96a should be renamed to GothEtal96\n",
      "AgamEtal09a should be renamed to AgamEtal09\n",
      "MouEtal04b should be renamed to MouEtal04\n",
      "SasaEtal96c should be renamed to SasaEtal96\n",
      "CronHao02a should be renamed to CronHao02\n",
      "HaynEtal09b should be renamed to HaynEtal09\n",
      "HaymTulv89b should be renamed to HaymTulv89\n",
      "RypmEtal99b should be renamed to RypmEtal99\n",
      "Klim96b should be renamed to Klim96\n",
      "YassStar11b should be renamed to YassStar11\n",
      "InouEtal94b should be renamed to InouEtal94\n",
      "HowaEtal09a should be renamed to HowaEtal09\n",
      "BurkEtal12a should be renamed to BurkEtal12\n",
      "CaplEtal00b should be renamed to CaplEtal00\n",
      "McClEtal03a should be renamed to McClEtal03\n",
      "Murd98b should be renamed to Murd98\n",
      "PolyEtal12a should be renamed to PolyEtal12\n",
      "WangEtal14a should be renamed to WangEtal14\n"
     ]
    }
   ],
   "source": [
    "bad_keys = check_keys(ids, gen_ids)\n",
    "\n",
    "if len(bad_keys) > 0:\n",
    "    print(f'{len(bad_keys)} incorrect keys found:\\n')\n",
    "    for x in bad_keys:\n",
    "        print(f'{x[0]} should be renamed to {x[1]}')\n",
    "else:\n",
    "    print('No incorrect keys found!')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Uz7-6pRYiGgH"
   },
   "outputs": [],
   "source": [
    "remove_fields = ['date-modified', 'date-added',\n",
    "                 'note', 'bdsk-url-1', 'pst', 'pmid', 'pmc',\n",
    "                 'mesh', 'keyword', 'journal-full', 'abstract',\n",
    "                 'mendeley-groups', 'file', 'bdsk-url-2', 'eprint',\n",
    "                 'arxivid', 'archiveprefix', 'ty', 'm3', 'l3',\n",
    "                 'howpublished', 'lccn', 'read', 'annote', 'owner',\n",
    "                 'timestamp', 'pii', 'zb', 'z9', 'z8' ,'times-cited',\n",
    "                 'publication-type', 'isi', 'language', 'stat', 'so',\n",
    "                 'sb', 'rf', 'pubm', 'pt', 'pl', 'phst', 'own', 'mhda',\n",
    "                 'jid', 'ip', 'edat', 'dcom', 'da', 'au', 'aid', 'affiliation',\n",
    "                 'lr', 'gr', 'jt', 'local-url', 'dep', 'mh', 'cin', 'ci',\n",
    "                 'comment', 'con', 'card', 'oto', 'ot', 'unique-id',\n",
    "                 'subject-category', 'number-of-cited-references', 'rating',\n",
    "                 'rn', 'oid', 'issn', 'isbn', 'doc-delivery-number']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "xN60kz1wh8EP"
   },
   "outputs": [],
   "source": [
    "keep_fields = [k for k in fields.keys() if k not in remove_fields]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bw-MKdv7oc4i",
    "outputId": "adebd73b-0c01-476f-9c94-c0e1def59b0f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['year',\n",
       " 'volume',\n",
       " 'title',\n",
       " 'pages',\n",
       " 'number',\n",
       " 'journal',\n",
       " 'author',\n",
       " 'ENTRYTYPE',\n",
       " 'ID',\n",
       " 'booktitle',\n",
       " 'publisher',\n",
       " 'editor',\n",
       " 'school',\n",
       " 'chapter',\n",
       " 'address',\n",
       " 'month',\n",
       " 'organization',\n",
       " 'doi',\n",
       " 'url',\n",
       " 'date',\n",
       " 'series',\n",
       " 'bdsk-file-1',\n",
       " 'type',\n",
       " 'institution',\n",
       " 'edition',\n",
       " 'location']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keep_fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SNq_ZR0l7c2y"
   },
   "source": [
    "To do:\n",
    "- ~~handle first-author surnames that start with lowercase characters~~\n",
    "- ~~better handling of curly braces to preserve name ordering~~\n",
    "- ~~better handling of escape characters~~\n",
    "- ensure bibtex file compiles and gets parsed correctly\n",
    "- ~~Check duplicate titles/authors (fail if detected)~~\n",
    "- Check bibtex keys.  Duplicates should be assigned a suffix of 'a', 'b', etc.\n",
    "- If keys match aside from suffix then still allow the bibtex file to \"pass\" as long as all \"matching\" keys are unique *and* all have suffixes *and* the suffixes span a, b, c, ..., etc. without gaps\n",
    "- Correct page numberings:\n",
    "  - Change hyphens to n-dashes\n",
    "  - Change m-dashes to n-dashes\n",
    "  - Remove spaces in page ranges\n",
    "  - Print a warning for strangely formatted pages: leading 0, non-digits, very large numbers (greater than 10K?) but allow bibtex file to pass\n",
    "- remove everything except for \"keep_fields\"\n",
    "  - Also add a \"force\" field that, when present, causes the checker to automatically pass that entry (if set to True); this will be used as a workaround for special cases not handled by the parser/checker\n",
    "- change all urls, dois, and page numbers to lowercase\n",
    "\n",
    "Clean up:\n",
    "- correct all \"strings\" to full journal names\n",
    "- correct all journal abbreviations to full journal names\n",
    "- Ensure no periods in journal names\n",
    "- Ensure no periods at the ends of affiliations or titles\n",
    "- Check for compressed initials (AA --> A A; A.A. --> A A; etc.)\n",
    "\n",
    "Bonus:\n",
    "- Use scholarly to verify information.  However, this is currently unreliable (server seems to hang frequently) and too slow to be viable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "G9N9JD9Wk3kM"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "bibtex checker.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
